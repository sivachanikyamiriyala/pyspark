import os
import time
import json
import logging
import requests 

from pyspark.sql import SparkSession,HiveContext
from pyspark.sql import *
from pyspark.sql import functions as f 
from pyspark.sql.functions import *
from pyspark.sql.types import *  

def rdbms():
	print("creation of sparkdriver")
	sparkdriver=SparkSession.builder.master('local').appName('dedede').config('spark.jars.packages','mysql:mysql-connector-java:5.1.45').getOrCreate()
	print("creation of sparkdriver is successful")
	print("creation of  data frame using rdbms")
	df=sparkdriver.read.format('jdbc').option('url','jdbc:mysql://localhost:3306').option('driver','com.mysql.jdbc.Driver').option('user','root').option('password','hadoop').option('dbtable','kalyan.orders').load()
	print(df.count())
	df.write.format('csv').option('delimiter','\t').save('hdfs://localhost:8020/hive/kalyan/ttttttt')


if __name__=="__main__":
	rdbms()


