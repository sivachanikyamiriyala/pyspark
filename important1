import os
import logging
import json
import requests

from pyspark.sql import SparkSession
from pyspark.sql import *
from pyspark.sql import functions
from pyspark.sql.functions import * 
from pyspark.sql.types import *

def rdbms():
	print("creation of sparksession")
	sparkdriver=SparkSession.builder.master('local').config('spark.jars.packages','mysql:mysql-connector-java:5.1.40').appName('siva').getOrCreate()
	print("creation of sparksesion completed")

	df=sparkdriver.read.format('jdbc').option('url','jdbc:mysql://localhost:3306').option('driver','com.mysql.jdbc.Driver').option('user','root').option('password','hadoop').option('dbtable','kalyan.orders').load()
	print("data frame created successfully")
	df.columns
	df.show(10) 


if __name__=="__main__":	                                  
	rdbms()